1. Introduction

Hello everyone,  

I am delighted to present our final-year project titled:  
"Generative Deep Learning for Multimodal Detection and Segmentation of Brain Tumors."

This work was carried out by myself, Houssem Lassoued, a student in industrial computer engineering, specializing in interconnected intelligent systems, under the expert guidance of Mr. Fathi Kallel and Mrs. Amira Echtioui. This project is also the result of a fruitful collaboration with the National Institute of Neurology Mongi Ben Hmida in Tunis, a public institution specialized in the management of neurological and neurosurgical pathologies.  

We will begin by outlining the problems to be addressed, then explore the contributions of deep learning techniques such as generative AI, classification, and segmentation of brain tumors to address them, before concluding with reflections on future improvements for this project.  



Problem Statement:

Brain tumors, although relatively rare—representing 1 to 2% of cancers in adults and 15 to 20% in children, affecting approximately 7 people per 100,000 each year in Tunisia—pose a significant danger. They cause severe disorders, including motor, cognitive, visual, and language impairments, as well as headaches, nausea, and vomiting. Early diagnosis is therefore essential to improve the quality of life of patients.  

However, traditional diagnostic methods, based on visual analysis by radiologists, are often time-consuming, subject to inter-individual variations, and prone to human errors.  

One of the main challenges in this field lies in the lack of balanced and representative data. Medical datasets are often limited, imbalanced between classes (healthy vs. tumorous), and difficult to access. In response to these challenges, our project aims to develop an automated intelligent system capable of detecting and segmenting brain tumors from medical images (CT and MRI).  

To achieve this, our approach is divided into four major steps:  

1. Generating synthetic data using generative AI techniques.  
2. Automated classification using transfer learning and ensemble learning approaches.  
3. Automated segmentation by leveraging transfer learning techniques and GAN-inspired methods.  
4. Deployment of the intelligent system in a user-friendly interface, designed to be easily usable by non-experts, such as radiologists.  


(1) Generation of Synthetic Data Using Generative AI Techniques

In this step, we explored several generative AI and transfer learning models, including:  

- CycleGAN: For translating CT images into MRI and vice versa.  
- CGAN: A conditional generative model guided by labels.  
- VAE: Based on a probabilistic encoder with a generator.  
- VAE-CGAN: A hybrid architecture combining VAE and CGAN.  

These models allow for the generation of realistic synthetic images while preserving essential anatomical features, effectively complementing real datasets and overcoming limitations related to data scarcity.  

Our models were trained on two datasets available on Kaggle:  

- A CT image dataset containing 4,521 images divided into healthy and tumorous classes.  
- An additional MRI dataset restructured to match the same organization as the CT dataset.  

The data underwent preparation through fusion, augmentation, resizing, and normalization steps before being used to configure the models with appropriate optimizers and loss functions.  

For synthetic data generation, CycleGAN was used to translate CT images into MRI. Subsequently, CGAN, VAE, and VAE-CGAN models were trained to generate synthetic datasets from real CT images and MRI images generated by CycleGAN.  

An ensemble classification model was then trained and evaluated on these datasets to select the most performant generator.  



(2) Automated Classification

We developed an ensemble classification model combining three CNN architectures (MobileNetV2, InceptionV3, EfficientNetV2S) and a meta-model Random Forest to produce final predictions from the outputs of the three CNN models. Among the generative models tested, CGAN proved to be the most effective for producing discriminative images.  

This refined generator, along with CycleGAN, was then used to enrich and balance the Brain CT Segmentation Dataset – 1000 studies from Kaggle, which suffered from significant imbalance (few tumorous images). The enriched and balanced dataset was used to train and evaluate the ensemble model, which will be integrated into our intelligent system for tumor detection.  

A comparison of the performance of the ensemble model, applied to an MRI dataset enriched by **CGAN**, with several recent classification methods highlights its superiority in this deep learning task.  


(3) Automated Segmentation

To create a complete intelligent system combining tumor detection and segmentation, we compared three architectures:  

- U-Net Classic  
- ResU-Net: With ResNet50 blocks.  
- ResU-Net GAN : ResU-Net + adversarial discriminator.  

These models, trained on the Brain CT Segmentation Dataset – 1000 studies, were preprocessed through several steps: extraction of tumor slices, contrast enhancement (grayscale windowing and histogram equalization), noise reduction using Gaussian filters, generation of MRI modalities with CycleGAN, and data augmentation through photometric and geometric transformations. Finally, the data were resized, normalized, and split into training, validation, and test sets.  

According to the Dice Score and Dice Loss metrics, ResU-Net GAN emerged as the most performant model among the proposed methods, thanks to residual layers and adversarial learning.  

Moreover, a comparison of these models with recent segmentation methods, evaluated using the Dice score, highlights the superiority of Res-UNet and Res-UNet-GAN in this deep learning task. The results of applying Grad-CAM show that Res-UNet and Res-UNet-GAN are the most interpretable models among the proposed methods.  



(4) Deployment

Finally, the intelligent system combining the ensemble model and **ResU-Net GAN** was deployed in software named **NeuroSegNet**, designed for use in hospital environments.  



Conclusion and Perspectives

In conclusion, among the generative models tested, CGAN demonstrated its ability to generate exploitable images for the classification task.  

Among the segmentation methods tested, ResU-Net GAN proved to be the most performant. Ultimately, ResU-Net GAN and the ensemble model were deployed in the NeuroSegNet software.  

Among the perspectives to explore, we can mention:  

- Improving the quality of generated synthetic images by optimizing the generative model's architecture, configuration, and hyperparameters, or by enhancing data preprocessing.  
- Validating the system on larger and more diverse cohorts.  
- Integrating multimodal data (clinical, genomic) to enrich the models.  

We hope that this work will inspire new research and contribute to improving the care of patients with brain tumors.  


5. Closing Remarks

I would like to warmly thank my supervisors, Mr. Fathi Kallel and Mrs. Amira Echtioui, as well as the entire team at the National Institute of Neurology Mongi Ben Hmida for their invaluable support.  

I remain at your disposal to answer any questions.  

Thank you for your attention!
